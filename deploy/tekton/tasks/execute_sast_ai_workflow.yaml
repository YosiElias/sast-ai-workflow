apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: execute-ai-analysis
spec:
  params:
    - name: PROJECT_NAME
      type: string
      default: ""
    - name: PROJECT_VERSION
      type: string
      default: ""
    - name: REPO_LOCAL_PATH
      type: string
    - name: INPUT_REPORT_FILE_PATH
      type: string
      default: ""
    - name: AGGREGATE_RESULTS_G_SHEET
      type: string
      default: ""
    - name: LLM_URL
      type: string
      default: ""
    - name: LLM_MODEL_NAME
      type: string
      default: ""
    - name: EMBEDDINGS_LLM_URL
      type: string
      default: ""
    - name: EMBEDDINGS_LLM_MODEL_NAME
      type: string
      default: ""
    - name: USE_KNOWN_FALSE_POSITIVE_FILE
      type: string
      description: "Whether to use known false positive file for filtering (true/false)"
      default: "true"
  workspaces:
    - name: source-workspace
    - name: false-positives-workspace
    - name: llm-credentials-ws
    - name: google-sa-json-ws
    - name: cache-workspace
  steps:
    - name: run-sast-ai-workflow
      image: quay.io/ecosystem-appeng/sast-ai-workflow:latest
      env:
        - name: PROJECT_NAME
          value: "$(params.PROJECT_NAME)"
        - name: PROJECT_VERSION
          value: "$(params.PROJECT_VERSION)"
        - name: REPO_LOCAL_PATH
          value: "$(params.REPO_LOCAL_PATH)"
        - name: KNOWN_FALSE_POSITIVE_FILE_PATH
          value: "$(workspaces.false-positives-workspace.path)/ignore.err"
        - name: USE_KNOWN_FALSE_POSITIVE_FILE
          value: "$(params.USE_KNOWN_FALSE_POSITIVE_FILE)"
        - name: INPUT_REPORT_FILE_PATH
          value: "$(params.INPUT_REPORT_FILE_PATH)"
        - name: AGGREGATE_RESULTS_G_SHEET
          value: "$(params.AGGREGATE_RESULTS_G_SHEET)"
        - name: LLM_URL
          value: "$(params.LLM_URL)"
        - name: LLM_MODEL_NAME
          value: "$(params.LLM_MODEL_NAME)"
        - name: EMBEDDINGS_LLM_URL
          value: "$(params.EMBEDDINGS_LLM_URL)"
        - name: EMBEDDINGS_LLM_MODEL_NAME
          value: "$(params.EMBEDDINGS_LLM_MODEL_NAME)"
        - name: LLM_API_KEY
          valueFrom:
            secretKeyRef:
              name: sast-ai-default-llm-creds
              key: llm_api_key
        - name: EMBEDDINGS_LLM_API_KEY
          valueFrom:
            secretKeyRef:
              name: sast-ai-default-llm-creds
              key: embeddings_llm_api_key
        - name: LLM_MODEL_NAME
          valueFrom:
            secretKeyRef:
              name: sast-ai-default-llm-creds
              key: llm_model_name
        - name: EMBEDDINGS_LLM_MODEL_NAME
          valueFrom:
            secretKeyRef:
              name: sast-ai-default-llm-creds
              key: embedding_llm_model_name
        - name: SERVICE_ACCOUNT_JSON_PATH
          value: "$(workspaces.google-sa-json-ws.path)/service_account.json"
        - name: ANALYSIS_SYSTEM_PROMPT
          valueFrom:
            configMapKeyRef:
              name: prompt-templates
              key: analysis_system_prompt
        - name: ANALYSIS_HUMAN_PROMPT
          valueFrom:
            configMapKeyRef:
              name: prompt-templates
              key: analysis_human_prompt
        - name: FILTER_SYSTEM_PROMPT
          valueFrom:
            configMapKeyRef:
              name: prompt-templates
              key: filter_system_prompt
        - name: FILTER_HUMAN_PROMPT
          valueFrom:
            configMapKeyRef:
              name: prompt-templates
              key: filter_human_prompt
        - name: RECOMMENDATIONS_PROMPT
          valueFrom:
            configMapKeyRef:
              name: prompt-templates
              key: recommendations_prompt
        - name: JUSTIFICATION_SUMMARY_SYSTEM_PROMPT
          valueFrom:
            configMapKeyRef:
              name: prompt-templates
              key: justification_summary_system_prompt
        - name: JUSTIFICATION_SUMMARY_HUMAN_PROMPT
          valueFrom:
            configMapKeyRef:
              name: prompt-templates
              key: justification_summary_human_prompt
        - name: EVALUATION_PROMPT
          valueFrom:
            configMapKeyRef:
              name: prompt-templates
              key: evaluation_prompt
        - name: TMPDIR # Directs tempfile module and others
          value: "$(workspaces.cache-workspace.path)/tmp" 
        - name: OUTPUT_FILE_PATH # For config.py, to save the Excel file to a workspace
          value: "$(workspaces.source-workspace.path)/sast_ai_output.xlsx" # Save in source-workspace (shared-workspace)
        - name: LIBCLANG_PATH
          value: "/usr/lib64/libclang.so.19.1.7"
      computeResources: 
        requests:
          ephemeral-storage: "1Gi"
        limits:
          ephemeral-storage: "2Gi"
      script: |
        #!/usr/bin/env sh
        set -ex

        echo "--- START: Storage Redirection Setup ---"
        # Create the custom TMPDIR on the PVC if it doesn't exist
        echo ">>> Ensuring custom TMPDIR exists: $(workspaces.cache-workspace.path)/tmp"
        mkdir -p "$(workspaces.cache-workspace.path)/tmp"
        
        # Your existing debug commands (df -h, du -sh, etc.) are still good here
        echo ">> Overall disk usage (df -h):"
        df -h
        echo ">> Usage of default /tmp (du -sh /tmp):"
        du -sh /tmp || echo "/tmp not found or inaccessible"
        echo ">> Usage of PVC-backed TMPDIR ($(workspaces.cache-workspace.path)/tmp):"
        du -sh "$(workspaces.cache-workspace.path)/tmp" || echo "PVC TMPDIR not found or inaccessible"
        echo ">> Usage of cache-workspace root ($(workspaces.cache-workspace.path)):"
        du -sh "$(workspaces.cache-workspace.path)" || echo "cache-workspace not found or inaccessible"
        echo "--- END: Storage Redirection Setup ---"

        echo "Running SAST-AI-Workflow..."
        python /app/src/run.py

        
       